{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Dense, Lambda,Embedding, Conv1D,Conv2D\n",
        "from tensorflow.keras.layers import MaxPool1D,Dropout, Lambda, Concatenate, Flatten\n",
        "from tensorflow.keras.layers import Multiply,Add\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "aWkkkuS5yr3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataprep:\n",
        "  def __init__(self,num_targets, num_negs,seq_len):\n",
        "    self.num_targets = num_targets\n",
        "    self.num_negs = num_negs\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def sequence_df(self):\n",
        "    url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml100K/ratings.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    df.rename(columns = {'userId':'user_id', 'movieId':'item_id'}, inplace = True)\n",
        "  # df\n",
        "    df['timestamp']= pd.to_datetime(df['timestamp'], unit = 's')\n",
        "    df.head(10)\n",
        "\n",
        "    def id_converter(df,x):\n",
        "      unique_params = df[x].unique()\n",
        "      num_unique = len(unique_params)\n",
        "      param_2enc = { i:j for i,j in enumerate(unique_params)}\n",
        "      enc_2param = { j:i for i,j in enumerate(unique_params)}\n",
        "\n",
        "\n",
        "      return num_unique , param_2enc, enc_2param\n",
        "\n",
        "    num_users, user_2enc ,enc_2user = id_converter(df,'user_id')\n",
        "    num_items, item_2enc ,enc_2item = id_converter(df,'item_id')\n",
        "\n",
        "    df['user_id'] = df['user_id'].map(enc_2user)\n",
        "    df['item_id'] = df['item_id'].map(enc_2item)\n",
        "\n",
        "    def time_sorter(df):\n",
        "    ### users and releated items were sorted according to time as function of increasing time \n",
        "      return(df.set_index(['user_id','timestamp']).sort_index().reset_index())\n",
        "\n",
        "    time_sorted_df = time_sorter(df)\n",
        "    time_sorted_df = time_sorted_df.drop(columns= ['timestamp','rating'])   \n",
        "    time_sorted_df.head(2)\n",
        "\n",
        "    def users_grouped(df,x):\n",
        "      return df.groupby([x]).aggregate(lambda tdf: tdf.unique().tolist()).reset_index()\n",
        "    # df = df.reset_index()\n",
        "    \n",
        "    grouped_df = users_grouped(time_sorted_df,'user_id')\n",
        "    grouped_df.head(3)\n",
        "\n",
        "    # def sequence_creator(df, self.seq_len, self.num_targets):\n",
        "    def sequence_creator(df):\n",
        "      users = []\n",
        "      seqs = []\n",
        "      targets = []\n",
        "\n",
        "      for i in range(len(grouped_df)):\n",
        "\n",
        "        for j in range(0,len(grouped_df['item_id'][i])-self.seq_len,self.num_targets):\n",
        "          users.append(i)\n",
        "          x = grouped_df['item_id'][i][j:j+self.seq_len+self.num_targets]\n",
        "          x1 = grouped_df['item_id'][i][j:j+self.seq_len]\n",
        "          seqs.append(list(x[0:self.seq_len]))\n",
        "          targets.append(np.array(x[-self.num_targets:]))\n",
        "\n",
        "      return (pd.DataFrame({'users':users,'sequences':seqs, 'targets':targets}))\n",
        "\n",
        "    L = 5\n",
        "    d = 2\n",
        "    sequenced_df = sequence_creator(grouped_df)\n",
        "    sequenced_df.head(2)\n",
        "\n",
        "    d = 2\n",
        "\n",
        "    tot2 = []\n",
        "    for j in range(self.num_negs):\n",
        "      tot = []\n",
        "      for i in range(len(sequenced_df)):\n",
        "        sampled_neg = np.random.randint(num_items)\n",
        "        x  = sequenced_df['users'][i]\n",
        "        grouped_df['item_id'][x]\n",
        "        while ((sampled_neg in sequenced_df['sequences'][i]) and  (sampled_neg in sequenced_df['sequences'][i] in grouped_df['item_id'][x] ) ):\n",
        "          sampled_neg = np.random.randint(num_items)\n",
        "        tot.append(sampled_neg)\n",
        "  \n",
        "      tot2.append(np.array(tot))\n",
        "\n",
        "    negs = np.array(tot2).T\n",
        "\n",
        "    sequenced_df['negs'] = list(negs)\n",
        "\n",
        "\n",
        "    return sequenced_df, num_users, num_items\n",
        "\n",
        "x = dataprep(1,1,5)\n",
        "df,num_users, num_items = x.sequence_df()\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "YcHTja9nyr0O",
        "outputId": "7f3db6a1-92ce-481d-a50d-fabe6a0a9212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   users           sequences targets    negs\n",
              "0      0  [16, 17, 19, 8, 9]    [10]  [4414]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8000d8bc-f933-4c46-9537-5ed85e36b4ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>users</th>\n",
              "      <th>sequences</th>\n",
              "      <th>targets</th>\n",
              "      <th>negs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[16, 17, 19, 8, 9]</td>\n",
              "      <td>[10]</td>\n",
              "      <td>[4414]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8000d8bc-f933-4c46-9537-5ed85e36b4ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8000d8bc-f933-4c46-9537-5ed85e36b4ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8000d8bc-f933-4c46-9537-5ed85e36b4ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expander1(x):\n",
        "    return (x[:,:,:,tf.newaxis])\n",
        "    \n",
        "def seqer2(x):\n",
        "    return (tf.squeeze(x, axis=2))\n",
        "\n",
        "def seqer1(x):\n",
        "    return (tf.squeeze(x, axis=1))\n",
        "\n",
        "TARGET_NUM = 1\n",
        "batch_size = 4096\n",
        "L=5\n",
        "d=16\n",
        "d_prime=4 \n",
        "drop_ratio=0.05\n",
        "num_factors = 5\n",
        "# num_factors = 10\n",
        "dims = num_factors"
      ],
      "metadata": {
        "id": "8JkTjjjEyrxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet = np.squeeze(np.dstack([df['targets'].astype('int'), df['negs'].astype('int')]))\n",
        "k = []\n",
        "sayac = 1\n",
        "for i in df['sequences']:\n",
        "  t =[]\n",
        "  for j in i:\n",
        "    t.append(int(j))\n",
        "  k.append(t)\n",
        "\n",
        "y_dummy = tf.ones( [len(df['users']),1])"
      ],
      "metadata": {
        "id": "QWdSzQwlyruJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = tf.keras.Input(shape = (1,), name = 'user_input')  ### kullanildi\n",
        "print('user_input_shape:',user_input.shape)\n",
        "seq_input = tf.keras.Input(shape = (L,), name = 'seq_input')  ### kullanildi\n",
        "print('seq_input_shape:',seq_input.shape)\n",
        "# doublet_input = tf.keras.Input(shape = (None,), name = 'doublet_input')\n",
        "doublet_input = tf.keras.Input(shape = (2,), name = 'doublet_input')\n",
        "print('dobulet_input_shape:',doublet_input.shape)\n",
        "seq_embedding = Embedding(num_items,num_factors, name = 'sequence_embedding')(seq_input)\n",
        "print('seq_embedding_shape:',seq_embedding.shape)\n",
        "seq_embedding = tf.expand_dims(seq_embedding, 3, name = 'sequence_embedding_expander')\n",
        "print('seq_embedding_expander_shape:',seq_embedding.shape)\n",
        "doublet_embedding = Embedding(num_items, num_factors*2,\n",
        "                              name = 'doublet_embedding')(doublet_input)## buyuk W\n",
        "print('doublet_embedding_shape:',doublet_embedding.shape)\n",
        "user_embedding = Embedding(num_users, num_factors,\n",
        "                               name = 'user_embedding')(user_input)\n",
        "print('user_embedding_shape:',user_embedding.shape)\n",
        "h = [i + 1 for i in range(L)]\n",
        "fc1_dim_v = d_prime * num_factors\n",
        "print('fc1_dim_v:',fc1_dim_v)\n",
        "out_v = Conv2D(d_prime,(L,1), name = 'convo_v')(seq_embedding)\n",
        "print('out_v_1_shape:',out_v.shape)\n",
        "out_v = Flatten(name = 'flatten_convo_v')(out_v)\n",
        "print('out_v_2_shape:',out_v.shape)\n",
        "out_hs = []\n",
        "for i in (h):\n",
        "  seq_mod = tf.keras.Sequential([\n",
        "           Conv2D(d, (i, num_factors)),\n",
        "           Lambda(seqer2),\n",
        "           MaxPool1D(L - i + 1),\n",
        "           Lambda(seqer1)                      \n",
        "          ])\n",
        "  out_hs.append(seq_mod(seq_embedding))\n",
        "# print('out_hs_shape:',np.array(out_hs).shape)\n",
        "out_h = tf.concat(out_hs, axis=1, name ='sequential_out') # galiba axis 2 olmali\n",
        "print('out_h_2_shape:',out_h.shape)\n",
        "out = tf.concat([out_v, out_h], axis = 1, name ='convo_concat')\n",
        "print('out_shape:',out.shape)\n",
        "dropout_layer = Dropout(0.05, name = 'dropout_layer')(out)\n",
        "z = Dense(dims, name = 'dense_layer', activation = 'relu')(dropout_layer)\n",
        "print('z_shape:',z.shape)\n",
        "flat_users = Flatten(name = 'flatten')(user_embedding)\n",
        "print('flat_users_shape:',flat_users.shape)\n",
        "x = tf.concat([z, flat_users], axis=1, name = 'x')\n",
        "print('x_shape:',x.shape)\n",
        "res = tf.matmul(doublet_embedding,tf.expand_dims(x,axis=-1))\n",
        "print('res_shape:',res.shape)\n",
        "doublet_embedding_b = Embedding(num_items, 1,\n",
        "                               name = 'doublet_embedding_b')(doublet_input)## kucuk b  \n",
        "res = res+doublet_embedding_b\n",
        "# res = tf.math.reduce_sum(res, axis = 1)\n",
        "res = tf.squeeze(res,axis =2)\n",
        "@tf.function\n",
        "def identity_loss(y_target, y_pred):\n",
        "# def identity_loss(y_target, y_pred):  \n",
        "  pos, neg = tf.split(y_pred,2,1)\n",
        "  positive_loss = -1*tf.math.reduce_mean(tf.math.log(tf.sigmoid(pos)))\n",
        "  negative_loss = -1*tf.math.reduce_mean(tf.math.log(1- tf.sigmoid(neg)))\n",
        "  total_loss = tf.math.add(positive_loss, negative_loss)\n",
        "  # return tf.math.reduce_mean(y_pred)\n",
        "  return total_loss\n",
        "caser_model =tf.keras.Model(inputs= [\n",
        "                                      user_input,\n",
        "                                      seq_input,\n",
        "                                      doublet_input\n",
        "                                      ],\n",
        "                            outputs = res,\n",
        "                            # outputs = x\n",
        "                            )\n",
        "\n",
        "caser_model.compile(loss = identity_loss,optimizer = 'Adam')\n",
        "\n",
        "caser_hist = caser_model.fit(\n",
        "                            [\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ],\n",
        "                y_dummy,\n",
        "                epochs = 2,  \n",
        "                batch_size = 512 \n",
        "                )\n"
      ],
      "metadata": {
        "id": "Yq-TE6ALy7po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7db1c55-e319-46f3-a34a-565e12aa7280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_input_shape: (None, 1)\n",
            "seq_input_shape: (None, 5)\n",
            "dobulet_input_shape: (None, 2)\n",
            "seq_embedding_shape: (None, 5, 5)\n",
            "seq_embedding_expander_shape: (None, 5, 5, 1)\n",
            "doublet_embedding_shape: (None, 2, 10)\n",
            "user_embedding_shape: (None, 1, 5)\n",
            "fc1_dim_v: 20\n",
            "out_v_1_shape: (None, 1, 5, 4)\n",
            "out_v_2_shape: (None, 20)\n",
            "out_h_2_shape: (None, 80)\n",
            "out_shape: (None, 100)\n",
            "z_shape: (None, 5)\n",
            "flat_users_shape: (None, 5)\n",
            "x_shape: (None, 10)\n",
            "res_shape: (None, 2, 1)\n",
            "Epoch 1/2\n",
            "189/189 [==============================] - 11s 30ms/step - loss: 1.2008\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.9319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### pred for pytorch\n",
        "# doublet_embedding_pos , doublet_embedding_neg = tf.split(doublet_embedding,2, axis = 1)\n",
        "# doublet_embedding_b_pos , doublet_embedding_b_neg = tf.split(doublet_embedding_b,2, axis = 1)\n",
        "# tf.math.reduce_sum((tf.squeeze(x, axis = 0) * doublet_embedding_pos), axis = 1\n",
        "#                    ) + doublet_embedding_b_pos \n",
        "\n",
        "\n",
        "# tf.math.reduce_sum((x * tf.squeeze(doublet_embedding_pos, axis=1)), axis = 1\n",
        "#                    ) + tf.squeeze(doublet_embedding_b_pos, axis =1 )\n",
        "# print('out_v', out_v.shape)\n",
        "# print('out_h', out_h.shape)\n",
        "# print('out', out.shape)\n",
        "# print('X',x.shape)\n",
        "# print('user_embedding',user_embedding.shape)\n",
        "# print('seq_embedding',seq_embedding.shape)\n",
        "# print('doublet_embedding',doublet_embedding.shape)\n",
        "# print('doublet_embedding_b',doublet_embedding_b.shape)\n",
        "# print('z',z.shape)\n",
        "# print('x',x.shape)\n",
        "# print('doublet_embedding_pos',doublet_embedding_pos.shape)\n",
        "# print('doublet_embedding_pos',tf.squeeze(doublet_embedding_b_pos, axis = 1).shape)"
      ],
      "metadata": {
        "id": "7JsiT8di5LMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Since model has custom loss which is called as troplet loss\n",
        "#### it is not possible to load the entire model without compiling after \n",
        "#### loading the model.\n",
        "#### To overcome this issue, we will keep the model and save the weights.\n"
      ],
      "metadata": {
        "id": "WF5vlz-rVHvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for layer in caser_model.layers:\n",
        "#   print(layer.name, layer)"
      ],
      "metadata": {
        "id": "JOSauaU6bj7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_weights = caser_model.get_layer('doublet_embedding').weights  ## shape=(9066, 20) split atabilirim\n",
        "doublet_embedding_b_weights = caser_model.get_layer('doublet_embedding_b').weights  ## shape=(9066, 1)\n",
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)\n",
        "flat_layer_weights = caser_model.get_layer('flatten').weights ## []\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "flat_users=tf.reshape(user_embedding_weights, \n",
        "           [tf.shape(user_embedding_weights)[1]*tf.shape(user_embedding_weights)[2]])"
      ],
      "metadata": {
        "id": "cMyzG5LtPzlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "\n",
        "user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])"
      ],
      "metadata": {
        "id": "EzwcdvPJRez4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights"
      ],
      "metadata": {
        "id": "EhzqzgfXTIY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.squeeze(preds)"
      ],
      "metadata": {
        "id": "T98cKk0DUTu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(dense_layer_weights).shape)\n",
        "print(np.array(user_embedding_weights).shape)\n",
        "print(np.array(user_embedding_weights_f).shape)"
      ],
      "metadata": {
        "id": "F3y_AyU_IcU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90364066-84db-4c8e-b2c9-36e9ed70facf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "(1, 671, 5)\n",
            "(3355,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.save_weights('drive/MyDrive/caser_model_weights')\n",
        "caser_model.load_weights('drive/MyDrive/caser_model_weights')\n",
        "# caser_model.summary()"
      ],
      "metadata": {
        "id": "WNHjf2aYkmpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8040d0c-8835-4222-9101-ddd67c095ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f80c82f8410>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "  dense_layer_weights = model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "  user_embedding_weights = model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "  doublet_embedding_b_weights = model.get_layer('doublet_embedding_1').weights\n",
        "  user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])\n",
        "  preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights\n",
        "  x = tf.squeeze(preds)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "5RsIFqqFk7Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.layers[-2].output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-grCyIBljm1",
        "outputId": "002aaa8c-eaa7-4721-c069-f9309bab39a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 2, 1) dtype=float32 (created by layer 'tf.__operators__.add')>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.get_layer('dense_layer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xRMB8lTmIJu",
        "outputId": "bce3327e-4163-4c8f-e783-a11f5d466543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f80c112ec90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "doublet_embedding_b_weights = caser_model.get_layer('doublet_embedding_b').weights\n",
        "user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])\n",
        "preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights\n",
        "x = tf.squeeze(preds)"
      ],
      "metadata": {
        "id": "9CHyrDzRnPu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_b_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-3].output)\n",
        "# doublet_embedding_b_model.summary()\n",
        "doublet_embedding_w_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-6].output)\n",
        "\n",
        "# doublet_embedding_w_model.summary()\n",
        "x_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-7].output)\n",
        "\n",
        "# x_model.summary()"
      ],
      "metadata": {
        "id": "zPotVT6moVXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_w_model_out = doublet_embedding_w_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])\n",
        "\n",
        "doublet_embedding_b_model_out = doublet_embedding_b_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])\n",
        "\n",
        "x_model_out = x_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])"
      ],
      "metadata": {
        "id": "nk5jAlv4_1nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(doublet_embedding_w_model_out.shape) #### belki buna ortadan split atabilirim\n",
        "print(doublet_embedding_b_model_out.shape) #### belki buna ortadan split atabilirim\n",
        "print(x_model_out.shape) #### belki buna ortadan split atabilirim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGUbyj6oAgd1",
        "outputId": "eb2d458c-c0ea-4c82-e71a-8006c3d5c0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 2, 10)\n",
            "(96649, 2, 1)\n",
            "(96649, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(dense_layer_weights).shape)\n",
        "print(np.array(user_embedding_weights).shape)\n",
        "print(np.array(user_embedding_weights_f).shape)"
      ],
      "metadata": {
        "id": "jKJjYxpaB81K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8765aa5-7c9f-450f-c93b-7b1e6106c73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "(1, 671, 5)\n",
            "(3355,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(tf.split(doublet_embedding_w_model_out,2,axis = 1)[0]).shape) #### belki buna ortadan split atabilirim\n",
        "print(np.array(tf.split(doublet_embedding_b_model_out,2,axis =1)[0]).shape) #### belki buna ortadan split atabilirim\n",
        "print(x_model_out.shape) #### belki buna ortadan split atabilirim"
      ],
      "metadata": {
        "id": "cuSFty2nN3dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c6021e-19b2-41e4-f59c-c13a05d4a601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 1, 10)\n",
            "(96649, 1, 1)\n",
            "(96649, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### prediction function\n",
        "w2_pred = tf.squeeze(tf.split(doublet_embedding_w_model_out,2,\n",
        "                              axis = 1)[0], axis = 1)\n",
        "b2_pred = tf.squeeze(tf.squeeze(tf.split(doublet_embedding_b_model_out,2,\n",
        "                              axis =1)[0], axis = 1), axis =1)\n",
        "# tf.matmul(x,)\n",
        "print(w2_pred.shape)\n",
        "print(b2_pred.shape)"
      ],
      "metadata": {
        "id": "x0oLzLqlzdsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e94adc5-6d33-4763-c580-17d67367a2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 10)\n",
            "(96649,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR0QQ--J_3gb",
        "outputId": "6a77cc13-c2d1-4ad9-bb67-e9d78c2923fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([96649, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalo = tf.math.reduce_sum((x_model_out*w2_pred) ,axis =1) + b2_pred"
      ],
      "metadata": {
        "id": "b_jIpO_XAfkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eccd431-6aa2-4d1b-c79a-b2b771e137ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(96649,), dtype=float32, numpy=\n",
              "array([1.8717275, 1.1254894, 1.6261234, ..., 0.4317628, 1.0245713,\n",
              "       1.1817822], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QxH7FKw7A607"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "j_junk1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}