{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Dense, Lambda,Embedding, Conv1D,Conv2D\n",
        "from tensorflow.keras.layers import MaxPool1D,Dropout, Lambda, Concatenate, Flatten\n",
        "from tensorflow.keras.layers import Multiply,Add\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aWkkkuS5yr3c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataprep:\n",
        "  def __init__(self,num_targets, num_negs,seq_len):\n",
        "    self.num_targets = num_targets\n",
        "    self.num_negs = num_negs\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def sequence_df(self):\n",
        "    url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml100K/ratings.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    df.rename(columns = {'userId':'user_id', 'movieId':'item_id'}, inplace = True)\n",
        "  # df\n",
        "    df['timestamp']= pd.to_datetime(df['timestamp'], unit = 's')\n",
        "    df.head(10)\n",
        "\n",
        "    def id_converter(df,x):\n",
        "      unique_params = df[x].unique()\n",
        "      num_unique = len(unique_params)\n",
        "      param_2enc = { i:j for i,j in enumerate(unique_params)}\n",
        "      enc_2param = { j:i for i,j in enumerate(unique_params)}\n",
        "\n",
        "\n",
        "      return num_unique , param_2enc, enc_2param\n",
        "\n",
        "    num_users, user_2enc ,enc_2user = id_converter(df,'user_id')\n",
        "    num_items, item_2enc ,enc_2item = id_converter(df,'item_id')\n",
        "\n",
        "    df['user_id'] = df['user_id'].map(enc_2user)\n",
        "    df['item_id'] = df['item_id'].map(enc_2item)\n",
        "\n",
        "    def time_sorter(df):\n",
        "    ### users and releated items were sorted according to time as function of increasing time \n",
        "      return(df.set_index(['user_id','timestamp']).sort_index().reset_index())\n",
        "\n",
        "    time_sorted_df = time_sorter(df)\n",
        "    time_sorted_df = time_sorted_df.drop(columns= ['timestamp','rating'])   \n",
        "    time_sorted_df.head(2)\n",
        "\n",
        "    def users_grouped(df,x):\n",
        "      return df.groupby([x]).aggregate(lambda tdf: tdf.unique().tolist()).reset_index()\n",
        "    # df = df.reset_index()\n",
        "    \n",
        "    grouped_df = users_grouped(time_sorted_df,'user_id')\n",
        "    grouped_df.head(3)\n",
        "\n",
        "    # def sequence_creator(df, self.seq_len, self.num_targets):\n",
        "    def sequence_creator(df):\n",
        "      users = []\n",
        "      seqs = []\n",
        "      targets = []\n",
        "\n",
        "      for i in range(len(grouped_df)):\n",
        "\n",
        "        for j in range(0,len(grouped_df['item_id'][i])-self.seq_len,self.num_targets):\n",
        "          users.append(i)\n",
        "          x = grouped_df['item_id'][i][j:j+self.seq_len+self.num_targets]\n",
        "          x1 = grouped_df['item_id'][i][j:j+self.seq_len]\n",
        "          seqs.append(list(x[0:self.seq_len]))\n",
        "          targets.append(np.array(x[-self.num_targets:]))\n",
        "\n",
        "      return (pd.DataFrame({'users':users,'sequences':seqs, 'targets':targets}))\n",
        "\n",
        "    L = 5\n",
        "    d = 2\n",
        "    sequenced_df = sequence_creator(grouped_df)\n",
        "    sequenced_df.head(2)\n",
        "\n",
        "    d = 2\n",
        "\n",
        "    tot2 = []\n",
        "    for j in range(self.num_negs):\n",
        "      tot = []\n",
        "      for i in range(len(sequenced_df)):\n",
        "        sampled_neg = np.random.randint(num_items)\n",
        "        x  = sequenced_df['users'][i]\n",
        "        grouped_df['item_id'][x]\n",
        "        while ((sampled_neg in sequenced_df['sequences'][i]) and  (sampled_neg in sequenced_df['sequences'][i] in grouped_df['item_id'][x] ) ):\n",
        "          sampled_neg = np.random.randint(num_items)\n",
        "        tot.append(sampled_neg)\n",
        "  \n",
        "      tot2.append(np.array(tot))\n",
        "\n",
        "    negs = np.array(tot2).T\n",
        "\n",
        "    sequenced_df['negs'] = list(negs)\n",
        "\n",
        "\n",
        "    return sequenced_df, num_users, num_items\n",
        "\n",
        "x = dataprep(1,1,5)\n",
        "df,num_users, num_items = x.sequence_df()\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "YcHTja9nyr0O",
        "outputId": "998415fc-eb61-47cc-c420-17a709df94d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   users           sequences targets    negs\n",
              "0      0  [16, 17, 19, 8, 9]    [10]  [7907]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeb2d6ea-c224-4c7f-aea3-97d76ebe3986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>users</th>\n",
              "      <th>sequences</th>\n",
              "      <th>targets</th>\n",
              "      <th>negs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[16, 17, 19, 8, 9]</td>\n",
              "      <td>[10]</td>\n",
              "      <td>[7907]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeb2d6ea-c224-4c7f-aea3-97d76ebe3986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aeb2d6ea-c224-4c7f-aea3-97d76ebe3986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aeb2d6ea-c224-4c7f-aea3-97d76ebe3986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expander1(x):\n",
        "    return (x[:,:,:,tf.newaxis])\n",
        "    \n",
        "def seqer2(x):\n",
        "    return (tf.squeeze(x, axis=2))\n",
        "\n",
        "def seqer1(x):\n",
        "    return (tf.squeeze(x, axis=1))\n",
        "\n",
        "TARGET_NUM = 1\n",
        "batch_size = 4096\n",
        "L=5\n",
        "d=16\n",
        "d_prime=4 \n",
        "drop_ratio=0.05\n",
        "num_factors= 10\n",
        "dims = num_factors"
      ],
      "metadata": {
        "id": "8JkTjjjEyrxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet = np.squeeze(np.dstack([df['targets'].astype('int'), df['negs'].astype('int')]))\n",
        "k = []\n",
        "sayac = 1\n",
        "for i in df['sequences']:\n",
        "  t =[]\n",
        "  for j in i:\n",
        "    t.append(int(j))\n",
        "  k.append(t)\n",
        "\n",
        "y_dummy = tf.ones( [len(df['users']),1])"
      ],
      "metadata": {
        "id": "QWdSzQwlyruJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = tf.keras.Input(shape = (1,), name = 'user_input')  ### kullanildi\n",
        "seq_input = tf.keras.Input(shape = (L,), name = 'seq_input')  ### kullanildi\n",
        "# doublet_input = tf.keras.Input(shape = (None,), name = 'doublet_input')\n",
        "doublet_input = tf.keras.Input(shape = (2,), name = 'doublet_input')\n",
        "\n",
        "seq_embedding = Embedding(num_items,num_factors, name = 'sequence_embedding')(seq_input)\n",
        "seq_embedding = tf.expand_dims(seq_embedding, 3, name = 'sequence_embedding_expander')\n",
        "doublet_embedding = Embedding(num_items, num_factors*2,\n",
        "                              name = 'doublet_embedding')(doublet_input)## buyuk W\n",
        "\n",
        "user_embedding = Embedding(num_users, num_factors,\n",
        "                               name = 'user_embedding')(user_input)\n",
        "\n",
        "h = [i + 1 for i in range(L)]\n",
        "fc1_dim_v = d_prime * num_factors\n",
        "out_v = Conv2D(d_prime,(L,1), name = 'convo_v')(seq_embedding)\n",
        "out_v = Flatten(name = 'flatten_convo_v')(out_v)\n",
        "\n",
        "out_hs = []\n",
        "for i in (h):\n",
        "  seq_mod = tf.keras.Sequential([\n",
        "           Conv2D(d, (i, num_factors)),\n",
        "           Lambda(seqer2),\n",
        "           MaxPool1D(L - i + 1),\n",
        "           Lambda(seqer1)                      \n",
        "          ])\n",
        "  out_hs.append(seq_mod(seq_embedding))\n",
        "\n",
        "out_h = tf.concat(out_hs, axis=1, name ='sequential_out') # galiba axis 2 olmali\n",
        "out = tf.concat([out_v, out_h], axis = 1, name ='convo_concat')\n",
        "dropout_layer = Dropout(0.05, name = 'dropout_layer')(out)\n",
        "z = Dense(10, name = 'dense_layer', activation = 'relu')(dropout_layer)\n",
        "flat_users = Flatten(name = 'flatten')(user_embedding)\n",
        "x = tf.concat([z, flat_users], axis=1, name = 'x')\n",
        "res = tf.matmul(doublet_embedding,tf.expand_dims(x,axis=-1))\n",
        "\n",
        "doublet_embedding_b = Embedding(num_items, 1,\n",
        "                               name = 'doublet_embedding_1')(doublet_input)## kucuk b  \n",
        "res = res+doublet_embedding_b\n",
        "# res = tf.math.reduce_sum(res, axis = 1)\n",
        "res = tf.squeeze(res,axis =2)\n",
        "@tf.function\n",
        "def identity_loss(y_target, y_pred):\n",
        "# def identity_loss(y_target, y_pred):  \n",
        "  pos, neg = tf.split(y_pred,2,1)\n",
        "  positive_loss = -1*tf.math.reduce_mean(tf.math.log(tf.sigmoid(pos)))\n",
        "  negative_loss = -1*tf.math.reduce_mean(tf.math.log(1- tf.sigmoid(neg)))\n",
        "  total_loss = tf.math.add(positive_loss, negative_loss)\n",
        "  # return tf.math.reduce_mean(y_pred)\n",
        "  return total_loss\n",
        "caser_model =tf.keras.Model(inputs= [\n",
        "                                      user_input,\n",
        "                                      seq_input,\n",
        "                                      doublet_input\n",
        "                                      ],\n",
        "                            outputs = res,\n",
        "                            # outputs = x\n",
        "                            )\n",
        "\n",
        "caser_model.compile(loss = identity_loss,optimizer = 'Adam')\n",
        "\n",
        "caser_hist = caser_model.fit(\n",
        "                            [\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ],\n",
        "                y_dummy,\n",
        "                epochs = 2,  \n",
        "                batch_size = 512 \n",
        "                )\n"
      ],
      "metadata": {
        "id": "Yq-TE6ALy7po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07165484-e900-46bb-a056-a781ddf3c37a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "189/189 [==============================] - 11s 35ms/step - loss: 1.1662\n",
            "Epoch 2/2\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 0.9141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### pred for pytorch\n",
        "# doublet_embedding_pos , doublet_embedding_neg = tf.split(doublet_embedding,2, axis = 1)\n",
        "# doublet_embedding_b_pos , doublet_embedding_b_neg = tf.split(doublet_embedding_b,2, axis = 1)\n",
        "# tf.math.reduce_sum((tf.squeeze(x, axis = 0) * doublet_embedding_pos), axis = 1\n",
        "#                    ) + doublet_embedding_b_pos \n",
        "\n",
        "\n",
        "# tf.math.reduce_sum((x * tf.squeeze(doublet_embedding_pos, axis=1)), axis = 1\n",
        "#                    ) + tf.squeeze(doublet_embedding_b_pos, axis =1 )\n",
        "# print('out_v', out_v.shape)\n",
        "# print('out_h', out_h.shape)\n",
        "# print('out', out.shape)\n",
        "# print('X',x.shape)\n",
        "# print('doublet_embedding',doublet_embedding.shape)\n",
        "# print('doublet_embedding_b',doublet_embedding_b.shape)\n",
        "# print('z',z.shape)\n",
        "# print('x',x.shape)\n",
        "# print('doublet_embedding_pos',doublet_embedding_pos.shape)\n",
        "# print('doublet_embedding_pos',tf.squeeze(doublet_embedding_b_pos, axis = 1).shape)"
      ],
      "metadata": {
        "id": "7JsiT8di5LMO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Since model has custom loss which is called as troplet loss\n",
        "#### it is not possible to load the entire model without compiling after \n",
        "#### loading the model.\n",
        "#### To overcome this issue, we will keep the model and save the weights.\n"
      ],
      "metadata": {
        "id": "WF5vlz-rVHvt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eXRBFc-xg3Jt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in caser_model.layers:\n",
        "  print(layer.name, layer)"
      ],
      "metadata": {
        "id": "JOSauaU6bj7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7da2d1f-b5ca-4516-93c8-8d6002cd5359"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq_input <keras.engine.input_layer.InputLayer object at 0x7f2dcda83610>\n",
            "sequence_embedding <keras.layers.embeddings.Embedding object at 0x7f2dca60a910>\n",
            "tf.expand_dims <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dcda66390>\n",
            "convo_v <keras.layers.convolutional.Conv2D object at 0x7f2dc9d3ac50>\n",
            "sequential <keras.engine.sequential.Sequential object at 0x7f2dc9cff410>\n",
            "sequential_1 <keras.engine.sequential.Sequential object at 0x7f2dc9cbbd50>\n",
            "sequential_2 <keras.engine.sequential.Sequential object at 0x7f2dca60a110>\n",
            "sequential_3 <keras.engine.sequential.Sequential object at 0x7f2dc9c818d0>\n",
            "sequential_4 <keras.engine.sequential.Sequential object at 0x7f2dc9c12d90>\n",
            "flatten_convo_v <keras.layers.core.flatten.Flatten object at 0x7f2dc9d3a7d0>\n",
            "tf.concat <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9c1b850>\n",
            "tf.concat_1 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9c39f50>\n",
            "user_input <keras.engine.input_layer.InputLayer object at 0x7f2dcda8ea90>\n",
            "dropout_layer <keras.layers.core.dropout.Dropout object at 0x7f2dc9d3add0>\n",
            "user_embedding <keras.layers.embeddings.Embedding object at 0x7f2dc9dc1610>\n",
            "dense_layer <keras.layers.core.dense.Dense object at 0x7f2dc9c39d50>\n",
            "flatten <keras.layers.core.flatten.Flatten object at 0x7f2dc9c2bfd0>\n",
            "doublet_input <keras.engine.input_layer.InputLayer object at 0x7f2dca60a4d0>\n",
            "tf.concat_2 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9bd4450>\n",
            "doublet_embedding <keras.layers.embeddings.Embedding object at 0x7f2dca60af50>\n",
            "tf.expand_dims_1 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9bd8c90>\n",
            "tf.linalg.matmul <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9bd8dd0>\n",
            "doublet_embedding_1 <keras.layers.embeddings.Embedding object at 0x7f2dc9bd87d0>\n",
            "tf.__operators__.add <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9be3250>\n",
            "tf.compat.v1.squeeze <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f2dc9be30d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_weights = caser_model.get_layer('doublet_embedding').weights  ## shape=(9066, 20) split atabilirim\n",
        "doublet_embedding_b_weights = caser_model.get_layer('doublet_embedding_1').weights  ## shape=(9066, 1)\n",
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)\n",
        "flat_layer_weights = caser_model.get_layer('flatten').weights ## []\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "flat_users=tf.reshape(user_embedding_weights, \n",
        "           [tf.shape(user_embedding_weights)[1]*tf.shape(user_embedding_weights)[2]])"
      ],
      "metadata": {
        "id": "cMyzG5LtPzlr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "\n",
        "user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])"
      ],
      "metadata": {
        "id": "EzwcdvPJRez4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights"
      ],
      "metadata": {
        "id": "EhzqzgfXTIY3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(preds)"
      ],
      "metadata": {
        "id": "T98cKk0DUTu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a1944b-61f7-496d-e9c3-d2157f65fe3b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9066,), dtype=float32, numpy=\n",
              "array([ 0.22081602, -0.15602247,  0.07991972, ...,  0.11387606,\n",
              "        0.4849578 ,  0.3005153 ], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "metadata": {
        "id": "F3y_AyU_IcU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcc85cc-fcb5-4bd7-ce1d-efa96c9f34e7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9066,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# caser_model.save('')"
      ],
      "metadata": {
        "id": "jUYWwY3E0aj7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import os\n",
        "# os.listdir('drive/MyDrive')\n"
      ],
      "metadata": {
        "id": "SRFqWSId0bXb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.save_weights('drive/MyDrive/caser_model_weights')"
      ],
      "metadata": {
        "id": "WNHjf2aYkmpW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.load_weights('drive/MyDrive/caser_model_weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WClAU9qolAje",
        "outputId": "ff463520-1879-48a3-98f0-bfb3e374eba1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2dc827c4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYeohlpUliU5",
        "outputId": "9b7e51bf-c240-4b3e-e8a6-a1a95cc49e23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " seq_input (InputLayer)         [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " sequence_embedding (Embedding)  (None, 5, 10)       90660       ['seq_input[0][0]']              \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, 5, 10, 1)     0           ['sequence_embedding[0][0]']     \n",
            "                                                                                                  \n",
            " convo_v (Conv2D)               (None, 1, 10, 4)     24          ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 16)           176         ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 16)           336         ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 16)           496         ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 16)           656         ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)      (None, 16)           816         ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " flatten_convo_v (Flatten)      (None, 40)           0           ['convo_v[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 80)           0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_1[0][0]',           \n",
            "                                                                  'sequential_2[0][0]',           \n",
            "                                                                  'sequential_3[0][0]',           \n",
            "                                                                  'sequential_4[0][0]']           \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, 120)          0           ['flatten_convo_v[0][0]',        \n",
            "                                                                  'tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dropout_layer (Dropout)        (None, 120)          0           ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " user_embedding (Embedding)     (None, 1, 10)        6710        ['user_input[0][0]']             \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 10)           1210        ['dropout_layer[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 10)           0           ['user_embedding[0][0]']         \n",
            "                                                                                                  \n",
            " doublet_input (InputLayer)     [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.concat_2 (TFOpLambda)       (None, 20)           0           ['dense_layer[0][0]',            \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " doublet_embedding (Embedding)  (None, 2, 20)        181320      ['doublet_input[0][0]']          \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 20, 1)        0           ['tf.concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLambda)  (None, 2, 1)         0           ['doublet_embedding[0][0]',      \n",
            "                                                                  'tf.expand_dims_1[0][0]']       \n",
            "                                                                                                  \n",
            " doublet_embedding_1 (Embedding  (None, 2, 1)        9066        ['doublet_input[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 2, 1)        0           ['tf.linalg.matmul[0][0]',       \n",
            " da)                                                              'doublet_embedding_1[0][0]']    \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (None, 2)           0           ['tf.__operators__.add[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 291,470\n",
            "Trainable params: 291,470\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model):\n",
        "  dense_layer_weights = model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "  user_embedding_weights = model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "  doublet_embedding_b_weights = model.get_layer('doublet_embedding_1').weights\n",
        "  user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])\n",
        "  preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights\n",
        "  x = tf.squeeze(preds)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "5RsIFqqFk7Op"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.layers[-2].output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-grCyIBljm1",
        "outputId": "9196f883-3a09-4ea6-f962-fd799b7131bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 2, 1) dtype=float32 (created by layer 'tf.__operators__.add')>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.get_layer('dense_layer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xRMB8lTmIJu",
        "outputId": "6e12cd5a-5dd1-4713-8db2-dadf6b937516"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7f2dc9c39d50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense_layer_weights = caser_model.get_layer('dense_layer').weights ## k1 : shape=(120, 10) , k2 : shape=(10,)  Z\n",
        "user_embedding_weights = caser_model.get_layer('user_embedding').weights  ## shape=(671, 10)\n",
        "doublet_embedding_b_weights = caser_model.get_layer('doublet_embedding_1').weights\n",
        "user_embedding_weights_f = tf.reshape(user_embedding_weights, tf.shape(user_embedding_weights)[0]*\n",
        "                                                              tf.shape(user_embedding_weights)[1]*\n",
        "                                                              tf.shape(user_embedding_weights)[2])\n",
        "preds = tf.math.reduce_sum(tf.concat([user_embedding_weights_f, dense_layer_weights[1]],axis = 0), axis =0)*doublet_embedding_b_weights\n",
        "x = tf.squeeze(preds)"
      ],
      "metadata": {
        "id": "9CHyrDzRnPu-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcooDqG_oECf",
        "outputId": "d9072077-df96-4173-b289-c38975d4e315"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'user_input')>,\n",
              " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'seq_input')>,\n",
              " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'doublet_input')>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_b_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-3].output)\n",
        "# doublet_embedding_b_model.summary()\n",
        "doublet_embedding_w_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-6].output)\n",
        "\n",
        "# doublet_embedding_w_model.summary()\n",
        "x_model = Model(inputs = caser_model.input,\n",
        "                         outputs = caser_model.layers[-7].output)\n",
        "\n",
        "# x_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPotVT6moVXI",
        "outputId": "8ca13c44-1b55-496b-d44b-af87fe4378fa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " doublet_input (InputLayer)     [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " user_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " seq_input (InputLayer)         [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " doublet_embedding_1 (Embedding  (None, 2, 1)        9066        ['doublet_input[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,066\n",
            "Trainable params: 9,066\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doublet_embedding_w_model_out = doublet_embedding_w_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])\n",
        "\n",
        "doublet_embedding_b_model_out = doublet_embedding_b_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])\n",
        "\n",
        "x_model_out = x_model([\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'),\n",
        "                                                                   df['negs'].astype('int') \n",
        "                                                                   ] ) ) ) ])"
      ],
      "metadata": {
        "id": "nk5jAlv4_1nm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(doublet_embedding_w_model_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGUbyj6oAgd1",
        "outputId": "7695c84a-6340-4ab3-e078-7f39293b9125"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 2, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(doublet_embedding_b_model_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj0mzN1BApHU",
        "outputId": "f7ea088b-4949-437f-f2fa-f76a46f84725"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_model_out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQiXN1_PAq51",
        "outputId": "49d68fad-34d6-448a-e81a-f3838532fecc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96649, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jKJjYxpaB81K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "j_junk1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}