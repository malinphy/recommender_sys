{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Dense, Lambda,Embedding, Conv1D,Conv2D\n",
        "from tensorflow.keras.layers import MaxPool1D,Dropout, Lambda, Concatenate, Flatten\n",
        "from tensorflow.keras.layers import Multiply,Add\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wIFMQ8-FVTHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataprep:\n",
        "  def __init__(self,num_targets, num_negs,seq_len):\n",
        "    self.num_targets = num_targets\n",
        "    self.num_negs = num_negs\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def sequence_df(self):\n",
        "    url = 'https://raw.githubusercontent.com/malinphy/datasets/main/ml100K/ratings.csv'\n",
        "    df = pd.read_csv(url)\n",
        "    df.rename(columns = {'userId':'user_id', 'movieId':'item_id'}, inplace = True)\n",
        "  # df\n",
        "    df['timestamp']= pd.to_datetime(df['timestamp'], unit = 's')\n",
        "    df.head(10)\n",
        "\n",
        "    def id_converter(df,x):\n",
        "      unique_params = df[x].unique()\n",
        "      num_unique = len(unique_params)\n",
        "      param_2enc = { i:j for i,j in enumerate(unique_params)}\n",
        "      enc_2param = { j:i for i,j in enumerate(unique_params)}\n",
        "\n",
        "\n",
        "      return num_unique , param_2enc, enc_2param\n",
        "\n",
        "    num_users, user_2enc ,enc_2user = id_converter(df,'user_id')\n",
        "    num_items, item_2enc ,enc_2item = id_converter(df,'item_id')\n",
        "\n",
        "    df['user_id'] = df['user_id'].map(enc_2user)\n",
        "    df['item_id'] = df['item_id'].map(enc_2item)\n",
        "\n",
        "    def time_sorter(df):\n",
        "    ### users and releated items were sorted according to time as function of increasing time \n",
        "      return(df.set_index(['user_id','timestamp']).sort_index().reset_index())\n",
        "\n",
        "    time_sorted_df = time_sorter(df)\n",
        "    time_sorted_df = time_sorted_df.drop(columns= ['timestamp','rating'])   \n",
        "    time_sorted_df.head(2)\n",
        "\n",
        "    def users_grouped(df,x):\n",
        "      return df.groupby([x]).aggregate(lambda tdf: tdf.unique().tolist()).reset_index()\n",
        "    # df = df.reset_index()\n",
        "    \n",
        "    grouped_df = users_grouped(time_sorted_df,'user_id')\n",
        "    grouped_df.head(3)\n",
        "\n",
        "    # def sequence_creator(df, self.seq_len, self.num_targets):\n",
        "    def sequence_creator(df):\n",
        "      users = []\n",
        "      seqs = []\n",
        "      targets = []\n",
        "\n",
        "      for i in range(len(grouped_df)):\n",
        "\n",
        "        for j in range(0,len(grouped_df['item_id'][i])-self.seq_len,self.num_targets):\n",
        "          users.append(i)\n",
        "          x = grouped_df['item_id'][i][j:j+self.seq_len+self.num_targets]\n",
        "          x1 = grouped_df['item_id'][i][j:j+self.seq_len]\n",
        "          seqs.append(list(x[0:self.seq_len]))\n",
        "          targets.append(np.array(x[-self.num_targets:]))\n",
        "\n",
        "      return (pd.DataFrame({'users':users,'sequences':seqs, 'targets':targets}))\n",
        "\n",
        "    L = 5\n",
        "    d = 2\n",
        "    sequenced_df = sequence_creator(grouped_df)\n",
        "    sequenced_df.head(2)\n",
        "\n",
        "    d = 2\n",
        "\n",
        "    tot2 = []\n",
        "    for j in range(self.num_negs):\n",
        "      tot = []\n",
        "      for i in range(len(sequenced_df)):\n",
        "        sampled_neg = np.random.randint(num_items)\n",
        "        x  = sequenced_df['users'][i]\n",
        "        grouped_df['item_id'][x]\n",
        "        while ((sampled_neg in sequenced_df['sequences'][i]) and  (sampled_neg in sequenced_df['sequences'][i] in grouped_df['item_id'][x] ) ):\n",
        "          sampled_neg = np.random.randint(num_items)\n",
        "        tot.append(sampled_neg)\n",
        "  \n",
        "      tot2.append(np.array(tot))\n",
        "\n",
        "    negs = np.array(tot2).T\n",
        "\n",
        "    sequenced_df['negs'] = list(negs)\n",
        "\n",
        "\n",
        "    return sequenced_df, num_users, num_items\n",
        "\n",
        "x = dataprep(1,1,5)\n",
        "df,num_users, num_items = x.sequence_df()\n",
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ouOp-gR2GPzP",
        "outputId": "b1224fcb-3179-4d18-a025-034efe4b9524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   users           sequences targets    negs\n",
              "0      0  [16, 17, 19, 8, 9]    [10]  [3605]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49d036f8-5cdd-4528-aea6-571dfeaad17a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>users</th>\n",
              "      <th>sequences</th>\n",
              "      <th>targets</th>\n",
              "      <th>negs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[16, 17, 19, 8, 9]</td>\n",
              "      <td>[10]</td>\n",
              "      <td>[3605]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49d036f8-5cdd-4528-aea6-571dfeaad17a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49d036f8-5cdd-4528-aea6-571dfeaad17a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49d036f8-5cdd-4528-aea6-571dfeaad17a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_locations = []\n",
        "for i in df['users'].unique():\n",
        "  # print(np.where(df['users'] == i)[0][-1])\n",
        "  test_locations.append(np.where(df['users']==i)[0][-1])\n",
        "\n",
        "print(len(df))\n",
        "\n",
        "df_test = df.loc[test_locations,:]\n",
        "df_train = df.drop(test_locations).reset_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJna3c0MGQR8",
        "outputId": "80ae22cf-f0da-42cf-a31a-d93fbdbeb4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def expander1(x):\n",
        "    return (x[:,:,:,tf.newaxis])\n",
        "    \n",
        "def seqer2(x):\n",
        "    return (tf.squeeze(x, axis=2))\n",
        "\n",
        "def seqer1(x):\n",
        "    return (tf.squeeze(x, axis=1))\n",
        "\n",
        "TARGET_NUM = 1\n",
        "batch_size = 4096\n",
        "L=5\n",
        "d=16\n",
        "d_prime=4 \n",
        "drop_ratio=0.05\n",
        "num_factors= 10\n",
        "dims = num_factors"
      ],
      "metadata": {
        "id": "0pcQ1QRUGb6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doublet = np.squeeze(np.dstack([df['targets'].astype('int'), df['negs'].astype('int')]))\n",
        "k = []\n",
        "sayac = 1\n",
        "for i in df['sequences']:\n",
        "  b =[]\n",
        "  for j in i:\n",
        "    b.append(int(j))\n",
        "  k.append(b)\n",
        "\n",
        "y_dummy = tf.ones( [len(df['users']),1])"
      ],
      "metadata": {
        "id": "4rPY2RD2JXuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input = tf.keras.Input(shape = (1,), name = 'user_input')  ### kullanildi\n",
        "# seq_input = tf.keras.Input(shape = (L,), name = 'seq_input')  ### kullanildi\n",
        "# doublet_input = tf.keras.Input(shape = (2,), name = 'doublet_input')\n",
        "\n",
        "# seq_embedding = Embedding(num_items,num_factors, name = 'sequence_embedding')(seq_input)\n",
        "# seq_embedding = tf.expand_dims(seq_embedding, 3)\n",
        "# doublet_embedding = Embedding(num_items, num_factors*2,\n",
        "#                               name = 'doublet_embedding')(doublet_input)## buyuk W\n",
        "# doublet_embedding_b = Embedding(num_items, 1,\n",
        "#                                name = 'doublet_embedding_1')(doublet_input)## kucuk b  \n",
        "# user_embedding = Embedding(num_users, num_factors,\n",
        "#                                name = 'user_embedding')(user_input)\n",
        "\n",
        "# h = [i + 1 for i in range(L)]\n",
        "# fc1_dim_v = d_prime * num_factors\n",
        "# out_v = Conv2D(d_prime,(L,1), name = 'convo_v')(seq_embedding)\n",
        "# out_v = Flatten(name = 'flatten_convo_v')(out_v)\n",
        "\n",
        "# out_hs = []\n",
        "# for i in (h):\n",
        "  \n",
        "#   seq_mod = tf.keras.Sequential([\n",
        "#            Conv2D(d, (i, num_factors)),\n",
        "#            Lambda(seqer2),\n",
        "#            MaxPool1D(L - i + 1),\n",
        "#            Lambda(seqer1)                      \n",
        "#           ])\n",
        "#   out_hs.append(seq_mod(seq_embedding))\n",
        "\n",
        "# out_h = tf.concat(out_hs, axis=1) # galiba axis 2 olmali\n",
        "# out = tf.concat([out_v, out_h], axis = 1)\n",
        "# dropout_layer = Dropout(0.05, name = 'dropout_layer')(out)\n",
        "# z = Dense(10, name = 'dense_layer')(dropout_layer)\n",
        "# x = tf.concat([z, Flatten()(user_embedding)], axis=1)\n",
        "# ####\n",
        "# bir = tf.math.reduce_sum(x*tf.squeeze(doublet_embedding, axis=0, name='sqeu'),\n",
        "#                          axis=1)# + b\n",
        "\n",
        "# res2 = (tf.reshape(bir, [2,1])+ doublet_embedding_b)  \n",
        "# res2 = tf.squeeze(res2,axis = [-1])                       \n",
        "# # print('bir.shpae', bir.shape)\n",
        "# # print(doublet_embedding.shape)\n",
        "# # print('swq',tf.squeeze(doublet_embedding, axis=0, name='sqeu'\n",
        "# # ).shape)\n",
        "# # print(doublet_embedding_b.shape)\n",
        "# # print('db',tf.squeeze(doublet_embedding_b, axis = 0, name='doublet_b'))\n",
        "# # ####\n",
        "# # print('x shape',x.shape)\n",
        "# #### bu kisma kadar\n",
        "\n",
        "# @tf.function\n",
        "# def identity_loss(y_target, y_pred):\n",
        "# # def identity_loss(y_target, y_pred):  \n",
        "#   pos, neg = tf.split(y_pred,2,1)\n",
        "#   # positive_loss = -1*tf.math.reduce_mean(tf.math.log(tf.sigmoid(pos)))\n",
        "#   # negative_loss = -1*tf.math.reduce_mean(tf.math.log(1- tf.sigmoid(neg)))\n",
        "#   # total_loss = tf.math.add(positive_loss, negative_loss)\n",
        "#   return tf.math.reduce_mean(y_pred)\n",
        "#   # return total_loss\n",
        "# caser_model =tf.keras.Model( inputs= [\n",
        "#                                       user_input,\n",
        "#                                       seq_input,\n",
        "#                                       doublet_input\n",
        "#                                       ],\n",
        "#                              outputs = res2 \n",
        "#                             # outputs = x\n",
        "#                             )\n",
        "# caser_model.compile(\n",
        "#     loss = identity_loss,\n",
        "#     # loss = tf.keras.losses.CategoricalHinge(),\n",
        "\n",
        "#     optimizer = 'Adam',\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print('x',x.shape)\n",
        "# print('res2', res2.shape)\n",
        "# caser_hist = caser_model.fit([tf.constant(df['users']),\n",
        "#                             tf.constant(k),\n",
        "#                 tf.constant(np.squeeze(np.dstack([df['targets'].astype('int'), df['negs'].astype('int')]))),\n",
        "#                 # np.squeeze(np.dstack([df['targets'], df['negs']]))\n",
        "#                 ],\n",
        "#                 y_dummy\n",
        "#                 , epochs = 1,\n",
        "#                 batch_size = 20\n",
        "#                 )"
      ],
      "metadata": {
        "id": "cxuJ-oWKGj0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = tf.keras.Input(shape = (1,), name = 'user_input')  ### kullanildi\n",
        "seq_input = tf.keras.Input(shape = (L,), name = 'seq_input')  ### kullanildi\n",
        "doublet_input = tf.keras.Input(shape = (2,), name = 'doublet_input')\n",
        "\n",
        "seq_embedding = Embedding(num_items,num_factors, name = 'sequence_embedding')(seq_input)\n",
        "seq_embedding = tf.expand_dims(seq_embedding, 3, name = 'sequence_embedding_expander')\n",
        "doublet_embedding = Embedding(num_items, num_factors*2,\n",
        "                              name = 'doublet_embedding')(doublet_input)## buyuk W\n",
        "\n",
        "doublet_embedding_b = Embedding(num_items, 1,\n",
        "                               name = 'doublet_embedding_1')(doublet_input)## kucuk b  \n",
        "\n",
        "user_embedding = Embedding(num_users, num_factors,\n",
        "                               name = 'user_embedding')(user_input)\n",
        "\n",
        "h = [i + 1 for i in range(L)]\n",
        "fc1_dim_v = d_prime * num_factors\n",
        "out_v = Conv2D(d_prime,(L,1), name = 'convo_v')(seq_embedding)\n",
        "out_v = Flatten(name = 'flatten_convo_v')(out_v)\n",
        "\n",
        "out_hs = []\n",
        "for i in (h):\n",
        "  seq_mod = tf.keras.Sequential([\n",
        "           Conv2D(d, (i, num_factors)),\n",
        "           Lambda(seqer2),\n",
        "           MaxPool1D(L - i + 1),\n",
        "           Lambda(seqer1)                      \n",
        "          ])\n",
        "  out_hs.append(seq_mod(seq_embedding))\n",
        "\n",
        "out_h = tf.concat(out_hs, axis=1, name ='sequential_out') # galiba axis 2 olmali\n",
        "out = tf.concat([out_v, out_h], axis = 1, name ='convo_concat')\n",
        "dropout_layer = Dropout(0.05, name = 'dropout_layer')(out)\n",
        "z = Dense(10, name = 'dense_layer')(dropout_layer)\n",
        "x = tf.concat([z, Flatten()(user_embedding)], axis=1, name = 'x')\n",
        "####\n",
        "bir = tf.math.reduce_sum(x*tf.squeeze(doublet_embedding, axis=0, name='sqeu'),\n",
        "                         axis=1)# + b\n",
        "\n",
        "res2 = (tf.reshape(bir, [2,1])+ doublet_embedding_b)  \n",
        "res2 = tf.squeeze(res2,axis = [-1])                       \n",
        "\n",
        "@tf.function\n",
        "def identity_loss(y_target, y_pred):\n",
        "# def identity_loss(y_target, y_pred):  \n",
        "  pos, neg = tf.split(y_pred,2,1)\n",
        "  positive_loss = -1*tf.math.reduce_mean(tf.math.log(tf.sigmoid(pos)))\n",
        "  negative_loss = -1*tf.math.reduce_mean(tf.math.log(1- tf.sigmoid(neg)))\n",
        "  total_loss = tf.math.add(positive_loss, negative_loss)\n",
        "  # return tf.math.reduce_mean(y_pred)\n",
        "  return total_loss\n",
        "caser_model =tf.keras.Model(inputs= [\n",
        "                                      user_input,\n",
        "                                      seq_input,\n",
        "                                      doublet_input\n",
        "                                      ],\n",
        "                             outputs = res2)\n",
        "\n",
        "caser_model.compile(loss = identity_loss,optimizer = 'Adam')\n",
        "\n",
        "caser_hist = caser_model.fit(\n",
        "                            [\n",
        "                              tf.constant(df['users']),\n",
        "                              tf.constant(k),\n",
        "                              tf.constant( np.squeeze( np.dstack( [ df[ 'targets'].astype('int'), df['negs'].astype('int') ] ) ) ) ],\n",
        "                y_dummy,\n",
        "                epochs = 1,  \n",
        "                batch_size = 1 ### BATCH SIZE DEGISINCE PROGRAM HATA VERIYOR, BUNU DUZELT\n",
        "                )\n",
        "\n"
      ],
      "metadata": {
        "id": "k3gUUcDPhruR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c65800e-93a4-47e7-ae2f-c05ff4657162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96649/96649 [==============================] - 682s 7ms/step - loss: 1.0920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTDoup2cFt2k",
        "outputId": "6db2518c-f966-492b-dffc-ea55c463bc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 80), dtype=tf.float32, name=None), name='tf.concat_10/concat:0', description=\"created by layer 'tf.concat_10'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in caser_model.layers:\n",
        "    print(layer.name, layer)"
      ],
      "metadata": {
        "id": "QP04NKtNmYH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60579365-027d-4e53-b16b-eda7348f5b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq_input <keras.engine.input_layer.InputLayer object at 0x7f183b333650>\n",
            "sequence_embedding <keras.layers.embeddings.Embedding object at 0x7f183b333f90>\n",
            "tf.expand_dims_4 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b341490>\n",
            "convo_v <keras.layers.convolutional.Conv2D object at 0x7f183b338ed0>\n",
            "sequential_20 <keras.engine.sequential.Sequential object at 0x7f183b35a250>\n",
            "sequential_21 <keras.engine.sequential.Sequential object at 0x7f183b35f690>\n",
            "sequential_22 <keras.engine.sequential.Sequential object at 0x7f183b2f4c50>\n",
            "sequential_23 <keras.engine.sequential.Sequential object at 0x7f183b309450>\n",
            "sequential_24 <keras.engine.sequential.Sequential object at 0x7f183b320850>\n",
            "flatten_convo_v <keras.layers.core.flatten.Flatten object at 0x7f183b331390>\n",
            "tf.concat_10 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b3254d0>\n",
            "tf.concat_11 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b236f90>\n",
            "user_input <keras.engine.input_layer.InputLayer object at 0x7f183b3335d0>\n",
            "dropout_layer <keras.layers.core.dropout.Dropout object at 0x7f183b320b90>\n",
            "user_embedding <keras.layers.embeddings.Embedding object at 0x7f183b345250>\n",
            "doublet_input <keras.engine.input_layer.InputLayer object at 0x7f183b333b50>\n",
            "dense_layer <keras.layers.core.dense.Dense object at 0x7f183b328d90>\n",
            "flatten_3 <keras.layers.core.flatten.Flatten object at 0x7f183b236850>\n",
            "doublet_embedding <keras.layers.embeddings.Embedding object at 0x7f183b341690>\n",
            "tf.concat_12 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b244190>\n",
            "tf.compat.v1.squeeze_5 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b240650>\n",
            "tf.math.multiply_3 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b2440d0>\n",
            "tf.math.reduce_sum_2 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b247710>\n",
            "tf.reshape_2 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b244bd0>\n",
            "doublet_embedding_1 <keras.layers.embeddings.Embedding object at 0x7f183b341d90>\n",
            "tf.__operators__.add_2 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b24e650>\n",
            "tf.compat.v1.squeeze_6 <keras.layers.core.tf_op_layer.TFOpLambda object at 0x7f183b23e0d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caser_model.get_layer('dense_layer').weights\n",
        "# print((caser_model.get_layer('doublet_embedding').weights))"
      ],
      "metadata": {
        "id": "iYNHqvVoados",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43050a15-a533-4cc4-bab6-040562e0ca7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_layer/kernel:0' shape=(120, 10) dtype=float32, numpy=\n",
              " array([[-2.2053210e-01,  3.8467854e-02,  3.2171238e-02, ...,\n",
              "          8.7354653e-02,  1.5342752e-03,  4.8971742e-02],\n",
              "        [-2.1870284e-01,  3.0579757e-02,  2.6617449e-02, ...,\n",
              "         -3.1368500e-01, -3.5402775e-02,  2.3689847e-02],\n",
              "        [-4.1116127e-05,  6.5744512e-02, -1.5977874e-01, ...,\n",
              "          4.1012902e-02, -2.4211276e-01, -1.2739694e-01],\n",
              "        ...,\n",
              "        [-3.0672597e-02, -9.6873432e-02, -6.6502705e-02, ...,\n",
              "          1.5705855e-01,  4.9339559e-02, -1.1708725e-01],\n",
              "        [ 1.8776618e-02, -5.9855349e-02, -1.0008163e-01, ...,\n",
              "          7.8845941e-02, -4.2184908e-02, -6.2889278e-02],\n",
              "        [-7.3913917e-02,  1.4212255e-01,  7.9315230e-02, ...,\n",
              "          1.1877959e-01,  1.2160551e-02, -7.0107281e-02]], dtype=float32)>,\n",
              " <tf.Variable 'dense_layer/bias:0' shape=(10,) dtype=float32, numpy=\n",
              " array([-0.12880032,  0.00959405, -0.0236844 ,  0.01437702,  0.03926595,\n",
              "         0.06203525, -0.10160863, -0.04298427,  0.11534938,  0.06815669],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict(model, user_id, sequence):\n",
        "print((caser_model.get_layer('doublet_embedding').weights))"
      ],
      "metadata": {
        "id": "7ncigi8wMgJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ff046d-7785-4e5c-a7c5-6bd3c385639c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'doublet_embedding/embeddings:0' shape=(9066, 20) dtype=float32, numpy=\n",
            "array([[ 0.491121  ,  0.07382999,  0.16407499, ..., -0.01226526,\n",
            "        -0.00761332,  0.05060099],\n",
            "       [ 0.31008473,  0.68797106,  0.39555055, ..., -0.40286288,\n",
            "        -0.31379974, -0.03876671],\n",
            "       [ 0.09514315,  0.2158661 ,  0.22104913, ..., -0.10127037,\n",
            "         0.31795242,  0.23064938],\n",
            "       ...,\n",
            "       [ 0.04864021, -0.15050004, -0.13373794, ...,  0.2117553 ,\n",
            "         0.14202695, -0.04507238],\n",
            "       [ 0.11061231, -0.18267606, -0.14490828, ..., -0.07370197,\n",
            "         0.00160368,  0.01920417],\n",
            "       [-0.06880045, -0.23289673, -0.41206938, ...,  0.23468111,\n",
            "         0.01205959, -0.3699207 ]], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# w = w\n",
        "tf.matmul(caser_model.get_layer('dense_layer').weights,\n",
        "          tf.squeeze(tf.transpose(caser_model.get_layer('doublet_embedding').weights),axis=[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FZvkv4c2pnaz",
        "outputId": "764837e5-7c12-4b33-eb32-a177527af36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-3288c3fec757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# w = w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m tf.matmul(caser_model.get_layer('dense_layer').weights,\n\u001b[0;32m----> 3\u001b[0;31m           tf.squeeze(tf.transpose(caser_model.get_layer('doublet_embedding').weights),axis=[-1]))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [120,10] != values[1].shape = [10] [Op:Pack] name: a"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(tf.transpose(caser_model.get_layer('doublet_embedding').weights),axis=[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFYidwxzpztO",
        "outputId": "f15974e8-9f2c-4540-887b-1f1e52b3b97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20, 9066), dtype=float32, numpy=\n",
              "array([[ 0.491121  ,  0.31008473,  0.09514315, ...,  0.04864021,\n",
              "         0.11061231, -0.06880045],\n",
              "       [ 0.07382999,  0.68797106,  0.2158661 , ..., -0.15050004,\n",
              "        -0.18267606, -0.23289673],\n",
              "       [ 0.16407499,  0.39555055,  0.22104913, ..., -0.13373794,\n",
              "        -0.14490828, -0.41206938],\n",
              "       ...,\n",
              "       [-0.01226526, -0.40286288, -0.10127037, ...,  0.2117553 ,\n",
              "        -0.07370197,  0.23468111],\n",
              "       [-0.00761332, -0.31379974,  0.31795242, ...,  0.14202695,\n",
              "         0.00160368,  0.01205959],\n",
              "       [ 0.05060099, -0.03876671,  0.23064938, ..., -0.04507238,\n",
              "         0.01920417, -0.3699207 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gUCk16h_p0oW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Caser_TF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}